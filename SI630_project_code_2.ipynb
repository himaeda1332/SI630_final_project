{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SI630_project_code_2.ipynb","provenance":[],"machine_shape":"hm","mount_file_id":"14hA31_ZLzsj4EjFv-izbMo5gqWEYXFX8","authorship_tag":"ABX9TyNQF4N/TRTXJsEsiWdfARix"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a412f6ad14534a468adaeefcd0aa36b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_63b5f4b43e6b47c38a3d946ac4a9f409","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_95483b39ac0043febf2ec130199e77cb","IPY_MODEL_d835221ef9bf44b29364c8f3fe899748"]}},"63b5f4b43e6b47c38a3d946ac4a9f409":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"95483b39ac0043febf2ec130199e77cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_12bde4c031ea42598ac44d04f16b52a7","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_31164de972fb4f889e7141f210b580eb"}},"d835221ef9bf44b29364c8f3fe899748":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_839eb78157434ee28a3817c59aebf730","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 338kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_200abf0e21c14aaba910d7a05a89ffd9"}},"12bde4c031ea42598ac44d04f16b52a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"31164de972fb4f889e7141f210b580eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"839eb78157434ee28a3817c59aebf730":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"200abf0e21c14aaba910d7a05a89ffd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2f04884853654f919d3021345542a4a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6602cb2cf372485a92f217720d522e63","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e3c5dd222827403e8b990004643d3d85","IPY_MODEL_1582f291479b46238e2480762bd5b480"]}},"6602cb2cf372485a92f217720d522e63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e3c5dd222827403e8b990004643d3d85":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_024ceaf5144c408abbc5de6336a4fcb4","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f72b505f0981453892d2beb301b39f43"}},"1582f291479b46238e2480762bd5b480":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_92304470715d4ab59b05c06735b67836","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:00&lt;00:00, 109B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d1ae6cb9d1b541a5aaedd04d8e1df89e"}},"024ceaf5144c408abbc5de6336a4fcb4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f72b505f0981453892d2beb301b39f43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"92304470715d4ab59b05c06735b67836":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d1ae6cb9d1b541a5aaedd04d8e1df89e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4265071a289a4a979852d92205e7a986":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f0ed9357d99945828e8091356133e0c8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1507e7cf5ec84226b567f1175cc012d6","IPY_MODEL_b866612d0c6d47a5b07ec9d0754426f5"]}},"f0ed9357d99945828e8091356133e0c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1507e7cf5ec84226b567f1175cc012d6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8cc5ae79802e433aa8117d4b2e3a29fc","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_58f46c25ac07416a8706d941cd48ee42"}},"b866612d0c6d47a5b07ec9d0754426f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_67a1d8b3374b422689a36b3e7793ab9b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:00&lt;00:00, 3.27MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_79d78766206048aab73bc2fae2e64a83"}},"8cc5ae79802e433aa8117d4b2e3a29fc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"58f46c25ac07416a8706d941cd48ee42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"67a1d8b3374b422689a36b3e7793ab9b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"79d78766206048aab73bc2fae2e64a83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bvZK9OhcrmEK","executionInfo":{"status":"ok","timestamp":1619560662071,"user_tz":240,"elapsed":10562,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"348f0df2-ed71-446a-80f8-57991adc76b3"},"source":["!pip install transformers -q\n","!pip install sentencepiece"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 2.1MB 6.5MB/s \n","\u001b[K     |████████████████████████████████| 901kB 21.8MB/s \n","\u001b[K     |████████████████████████████████| 3.3MB 33.8MB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 6.4MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.95\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B4Wy4EBeTMm4","executionInfo":{"status":"ok","timestamp":1619560662183,"user_tz":240,"elapsed":7688,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"18f99350-6d77-4aed-bfc5-3c7eeebce47f"},"source":["!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Tue Apr 27 21:57:42 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8TEL0TdaVpf7"},"source":["# 1.Import libraries"]},{"cell_type":"code","metadata":{"id":"xPqAEDmdr9SP","executionInfo":{"status":"ok","timestamp":1619564798736,"user_tz":240,"elapsed":186,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["# Importing stock libraries\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torch import nn\n","from torch import optim\n","\n","from torch.optim import AdamW\n","from transformers import get_linear_schedule_with_warmup\n","\n","from collections import defaultdict\n","import gc\n","\n","# Importing the T5 modules from huggingface/transformers\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","import sentencepiece\n","\n","from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error"],"execution_count":103,"outputs":[]},{"cell_type":"code","metadata":{"id":"N6-z_cIl72l0","executionInfo":{"status":"ok","timestamp":1619560774762,"user_tz":240,"elapsed":199,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["RANDOM_SEED = 42\n","np.random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":164,"referenced_widgets":["a412f6ad14534a468adaeefcd0aa36b9","63b5f4b43e6b47c38a3d946ac4a9f409","95483b39ac0043febf2ec130199e77cb","d835221ef9bf44b29364c8f3fe899748","12bde4c031ea42598ac44d04f16b52a7","31164de972fb4f889e7141f210b580eb","839eb78157434ee28a3817c59aebf730","200abf0e21c14aaba910d7a05a89ffd9","2f04884853654f919d3021345542a4a8","6602cb2cf372485a92f217720d522e63","e3c5dd222827403e8b990004643d3d85","1582f291479b46238e2480762bd5b480","024ceaf5144c408abbc5de6336a4fcb4","f72b505f0981453892d2beb301b39f43","92304470715d4ab59b05c06735b67836","d1ae6cb9d1b541a5aaedd04d8e1df89e","4265071a289a4a979852d92205e7a986","f0ed9357d99945828e8091356133e0c8","1507e7cf5ec84226b567f1175cc012d6","b866612d0c6d47a5b07ec9d0754426f5","8cc5ae79802e433aa8117d4b2e3a29fc","58f46c25ac07416a8706d941cd48ee42","67a1d8b3374b422689a36b3e7793ab9b","79d78766206048aab73bc2fae2e64a83"]},"id":"bKpckGKDsAZ3","executionInfo":{"status":"ok","timestamp":1619560787898,"user_tz":240,"elapsed":1571,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"f6c98e8f-247c-4e22-99c9-ab7442dcb455"},"source":["tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a412f6ad14534a468adaeefcd0aa36b9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f04884853654f919d3021345542a4a8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4265071a289a4a979852d92205e7a986","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"S2ZFQZHEWm-p"},"source":["## (1).Sample"]},{"cell_type":"code","metadata":{"id":"Cu5yeqdc8iLH","executionInfo":{"status":"ok","timestamp":1619560880139,"user_tz":240,"elapsed":315,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["sample_txt = 'When was I last outside? I am stuck at home for 2 weeks.'"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o-SqsBGr8UwJ","executionInfo":{"status":"ok","timestamp":1619560880714,"user_tz":240,"elapsed":180,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"2cdb6473-5332-44ac-cdf7-62ddd14a8170"},"source":["encoding = tokenizer.encode_plus(\n","    sample_txt,\n","    max_length=100,\n","    add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n","    return_token_type_ids=False,\n","    pad_to_max_length=True,\n","    return_attention_mask=True,\n","    return_tensors='pt', \n",")\n","encoding.keys()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["dict_keys(['input_ids', 'attention_mask'])"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l5gO2ZDL8qqF","executionInfo":{"status":"ok","timestamp":1619560883172,"user_tz":240,"elapsed":202,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"09900cc8-adf4-4d0e-8dc5-6c6065770811"},"source":["print(len(encoding['input_ids'][0]))\n","encoding['input_ids'][0]"],"execution_count":10,"outputs":[{"output_type":"stream","text":["100\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["tensor([ 101, 2043, 2001, 1045, 2197, 2648, 1029, 1045, 2572, 5881, 2012, 2188,\n","        2005, 1016, 3134, 1012,  102,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0])"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"DsWt58VLWub5"},"source":["# 2.Load dataset"]},{"cell_type":"code","metadata":{"id":"rkmi_sJQW1PB","executionInfo":{"status":"ok","timestamp":1619561007614,"user_tz":240,"elapsed":203,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["INPUT_PATH = 'input/'"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":462},"id":"QXpCUivCWx2D","executionInfo":{"status":"ok","timestamp":1619561024741,"user_tz":240,"elapsed":1088,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"2121c357-0b73-4444-926e-d188c7af1210"},"source":["df_info_all_v2 = pd.read_csv(INPUT_PATH + 'df_all_final.csv')\n","df_info_all_v2.head()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>uuid</th>\n","      <th>author</th>\n","      <th>country</th>\n","      <th>published</th>\n","      <th>image</th>\n","      <th>site</th>\n","      <th>site_category</th>\n","      <th>page_view</th>\n","      <th>fb_comment</th>\n","      <th>fb_likes</th>\n","      <th>fb_shares</th>\n","      <th>linkedin</th>\n","      <th>pinterest</th>\n","      <th>url</th>\n","      <th>date</th>\n","      <th>year</th>\n","      <th>month</th>\n","      <th>day</th>\n","      <th>weekday</th>\n","      <th>hour</th>\n","      <th>minute</th>\n","      <th>seccont</th>\n","      <th>noweek</th>\n","      <th>doc_topic</th>\n","      <th>log_share</th>\n","      <th>num_title_words</th>\n","      <th>num_words</th>\n","      <th>num_words_clean</th>\n","      <th>country_model</th>\n","      <th>site_model</th>\n","      <th>country_label</th>\n","      <th>site_label</th>\n","      <th>log_page</th>\n","      <th>positive</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9b265eb1f08a07a093f4e415f4878b5ccec71b0b</td>\n","      <td>David E. Sanger, Julian E. Barnes and Nicole P...</td>\n","      <td>US</td>\n","      <td>2021-03-15T01:58:58.000+02:00</td>\n","      <td>0</td>\n","      <td>www.msn.com</td>\n","      <td>tech</td>\n","      <td>578.0</td>\n","      <td>17</td>\n","      <td>28</td>\n","      <td>107</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>https://www.msn.com/en-us/news/politics/white-...</td>\n","      <td>2021-03-15 01:58:58</td>\n","      <td>2021</td>\n","      <td>3</td>\n","      <td>15</td>\n","      <td>Mon</td>\n","      <td>1</td>\n","      <td>58</td>\n","      <td>6314338.0</td>\n","      <td>11</td>\n","      <td>14</td>\n","      <td>4.682131</td>\n","      <td>11</td>\n","      <td>54</td>\n","      <td>26</td>\n","      <td>US</td>\n","      <td>www.msn.com</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>6.361302</td>\n","      <td>0.012595</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0d49c01d17674d04754b87cb7c5167a589934e61</td>\n","      <td>Marina Pitofsky</td>\n","      <td>US</td>\n","      <td>2021-03-15T01:58:57.000+02:00</td>\n","      <td>0</td>\n","      <td>www.msn.com</td>\n","      <td>tech</td>\n","      <td>578.0</td>\n","      <td>396</td>\n","      <td>3438</td>\n","      <td>84</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>https://www.msn.com/en-us/news/politics/rachel...</td>\n","      <td>2021-03-15 01:58:57</td>\n","      <td>2021</td>\n","      <td>3</td>\n","      <td>15</td>\n","      <td>Mon</td>\n","      <td>1</td>\n","      <td>58</td>\n","      <td>6314337.0</td>\n","      <td>11</td>\n","      <td>1</td>\n","      <td>4.442651</td>\n","      <td>10</td>\n","      <td>310</td>\n","      <td>177</td>\n","      <td>US</td>\n","      <td>www.msn.com</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>6.361302</td>\n","      <td>0.174687</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ad1d5c62864864e9ae3d36b487cc322f5bcbaf9c</td>\n","      <td>Kevin Rector</td>\n","      <td>US</td>\n","      <td>2021-03-15T01:51:00.000+02:00</td>\n","      <td>1</td>\n","      <td>www.latimes.com</td>\n","      <td>tech</td>\n","      <td>14.7</td>\n","      <td>19</td>\n","      <td>30</td>\n","      <td>22</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>https://www.latimes.com/california/story/2021-...</td>\n","      <td>2021-03-15 01:51:00</td>\n","      <td>2021</td>\n","      <td>3</td>\n","      <td>15</td>\n","      <td>Mon</td>\n","      <td>1</td>\n","      <td>51</td>\n","      <td>6313860.0</td>\n","      <td>11</td>\n","      <td>5</td>\n","      <td>3.135494</td>\n","      <td>12</td>\n","      <td>196</td>\n","      <td>104</td>\n","      <td>US</td>\n","      <td>other</td>\n","      <td>9</td>\n","      <td>3</td>\n","      <td>2.753661</td>\n","      <td>0.004682</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9314d252503ee1f811c29627ab629c5b799ef103</td>\n","      <td>Kim Lyons</td>\n","      <td>US</td>\n","      <td>2021-03-15T01:29:00.000+02:00</td>\n","      <td>1</td>\n","      <td>www.theverge.com</td>\n","      <td>tech</td>\n","      <td>31.9</td>\n","      <td>0</td>\n","      <td>17</td>\n","      <td>25</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>https://www.theverge.com/2021/3/14/22326012/ne...</td>\n","      <td>2021-03-15 01:29:00</td>\n","      <td>2021</td>\n","      <td>3</td>\n","      <td>15</td>\n","      <td>Mon</td>\n","      <td>1</td>\n","      <td>29</td>\n","      <td>6312540.0</td>\n","      <td>11</td>\n","      <td>1</td>\n","      <td>3.258097</td>\n","      <td>14</td>\n","      <td>415</td>\n","      <td>182</td>\n","      <td>US</td>\n","      <td>other</td>\n","      <td>9</td>\n","      <td>3</td>\n","      <td>3.493473</td>\n","      <td>0.006911</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cda04303d248fcdab575934d10d33b957e9691d6</td>\n","      <td>Des Erasmus</td>\n","      <td>US</td>\n","      <td>2021-03-15T01:22:32.000+02:00</td>\n","      <td>0</td>\n","      <td>www.msn.com</td>\n","      <td>tech</td>\n","      <td>578.0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>https://www.msn.com/en-za/news/other/the-lord-...</td>\n","      <td>2021-03-15 01:22:32</td>\n","      <td>2021</td>\n","      <td>3</td>\n","      <td>15</td>\n","      <td>Mon</td>\n","      <td>1</td>\n","      <td>22</td>\n","      <td>6312152.0</td>\n","      <td>11</td>\n","      <td>6</td>\n","      <td>2.484907</td>\n","      <td>16</td>\n","      <td>2262</td>\n","      <td>937</td>\n","      <td>US</td>\n","      <td>www.msn.com</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>6.361302</td>\n","      <td>0.005006</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                       uuid  ...  positive\n","0  9b265eb1f08a07a093f4e415f4878b5ccec71b0b  ...  0.012595\n","1  0d49c01d17674d04754b87cb7c5167a589934e61  ...  0.174687\n","2  ad1d5c62864864e9ae3d36b487cc322f5bcbaf9c  ...  0.004682\n","3  9314d252503ee1f811c29627ab629c5b799ef103  ...  0.006911\n","4  cda04303d248fcdab575934d10d33b957e9691d6  ...  0.005006\n","\n","[5 rows x 34 columns]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ijUneJrXSsc","executionInfo":{"status":"ok","timestamp":1619561274239,"user_tz":240,"elapsed":3547,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"2b441ea9-dbf1-4121-9081-4c9449f6fc04"},"source":["df_text_all = pd.read_csv(INPUT_PATH + 'text_all_clean.csv')\n","df_text_all.columns"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['uuid', 'title', 'text', 'clean_title', 'clean_text', 'num_words',\n","       'num_words_clean'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":434},"id":"OtcKkk9cXmky","executionInfo":{"status":"ok","timestamp":1619561310181,"user_tz":240,"elapsed":730,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"22fe710c-c805-4369-ee7f-b0d1f4d116ae"},"source":["df_info_all_v2 = df_info_all_v2.merge(df_text_all[['uuid', 'clean_title', 'clean_text']], left_on='uuid', right_on='uuid')\n","df_info_all_v2.head(3)"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>uuid</th>\n","      <th>author</th>\n","      <th>country</th>\n","      <th>published</th>\n","      <th>image</th>\n","      <th>site</th>\n","      <th>site_category</th>\n","      <th>page_view</th>\n","      <th>fb_comment</th>\n","      <th>fb_likes</th>\n","      <th>fb_shares</th>\n","      <th>linkedin</th>\n","      <th>pinterest</th>\n","      <th>url</th>\n","      <th>date</th>\n","      <th>year</th>\n","      <th>month</th>\n","      <th>day</th>\n","      <th>weekday</th>\n","      <th>hour</th>\n","      <th>minute</th>\n","      <th>seccont</th>\n","      <th>noweek</th>\n","      <th>doc_topic</th>\n","      <th>log_share</th>\n","      <th>num_title_words</th>\n","      <th>num_words</th>\n","      <th>num_words_clean</th>\n","      <th>country_model</th>\n","      <th>site_model</th>\n","      <th>country_label</th>\n","      <th>site_label</th>\n","      <th>log_page</th>\n","      <th>positive</th>\n","      <th>clean_title</th>\n","      <th>clean_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9b265eb1f08a07a093f4e415f4878b5ccec71b0b</td>\n","      <td>David E. Sanger, Julian E. Barnes and Nicole P...</td>\n","      <td>US</td>\n","      <td>2021-03-15T01:58:58.000+02:00</td>\n","      <td>0</td>\n","      <td>www.msn.com</td>\n","      <td>tech</td>\n","      <td>578.0</td>\n","      <td>17</td>\n","      <td>28</td>\n","      <td>107</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>https://www.msn.com/en-us/news/politics/white-...</td>\n","      <td>2021-03-15 01:58:58</td>\n","      <td>2021</td>\n","      <td>3</td>\n","      <td>15</td>\n","      <td>Mon</td>\n","      <td>1</td>\n","      <td>58</td>\n","      <td>6314338.0</td>\n","      <td>11</td>\n","      <td>14</td>\n","      <td>4.682131</td>\n","      <td>11</td>\n","      <td>54</td>\n","      <td>26</td>\n","      <td>US</td>\n","      <td>www.msn.com</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>6.361302</td>\n","      <td>0.012595</td>\n","      <td>white house weigh new cybersecurity approach f...</td>\n","      <td>washington sophisticated hack pull russia chin...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0d49c01d17674d04754b87cb7c5167a589934e61</td>\n","      <td>Marina Pitofsky</td>\n","      <td>US</td>\n","      <td>2021-03-15T01:58:57.000+02:00</td>\n","      <td>0</td>\n","      <td>www.msn.com</td>\n","      <td>tech</td>\n","      <td>578.0</td>\n","      <td>396</td>\n","      <td>3438</td>\n","      <td>84</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>https://www.msn.com/en-us/news/politics/rachel...</td>\n","      <td>2021-03-15 01:58:57</td>\n","      <td>2021</td>\n","      <td>3</td>\n","      <td>15</td>\n","      <td>Mon</td>\n","      <td>1</td>\n","      <td>58</td>\n","      <td>6314337.0</td>\n","      <td>11</td>\n","      <td>1</td>\n","      <td>4.442651</td>\n","      <td>10</td>\n","      <td>310</td>\n","      <td>177</td>\n","      <td>US</td>\n","      <td>www.msn.com</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>6.361302</td>\n","      <td>0.174687</td>\n","      <td>rachel maddow win grammy audio recording book</td>\n","      <td>© getty image rachel maddow win grammy audio r...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ad1d5c62864864e9ae3d36b487cc322f5bcbaf9c</td>\n","      <td>Kevin Rector</td>\n","      <td>US</td>\n","      <td>2021-03-15T01:51:00.000+02:00</td>\n","      <td>1</td>\n","      <td>www.latimes.com</td>\n","      <td>tech</td>\n","      <td>14.7</td>\n","      <td>19</td>\n","      <td>30</td>\n","      <td>22</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>https://www.latimes.com/california/story/2021-...</td>\n","      <td>2021-03-15 01:51:00</td>\n","      <td>2021</td>\n","      <td>3</td>\n","      <td>15</td>\n","      <td>Mon</td>\n","      <td>1</td>\n","      <td>51</td>\n","      <td>6313860.0</td>\n","      <td>11</td>\n","      <td>5</td>\n","      <td>3.135494</td>\n","      <td>12</td>\n","      <td>196</td>\n","      <td>104</td>\n","      <td>US</td>\n","      <td>other</td>\n","      <td>9</td>\n","      <td>3</td>\n","      <td>2.753661</td>\n","      <td>0.004682</td>\n","      <td>man fatally shoot los angeles county sheriff d...</td>\n","      <td>man fatally shoot los angeles county sheriff...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                       uuid  ...                                         clean_text\n","0  9b265eb1f08a07a093f4e415f4878b5ccec71b0b  ...  washington sophisticated hack pull russia chin...\n","1  0d49c01d17674d04754b87cb7c5167a589934e61  ...  © getty image rachel maddow win grammy audio r...\n","2  ad1d5c62864864e9ae3d36b487cc322f5bcbaf9c  ...    man fatally shoot los angeles county sheriff...\n","\n","[3 rows x 36 columns]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AVSc3FrR9_ju","executionInfo":{"status":"ok","timestamp":1619561030684,"user_tz":240,"elapsed":229,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"6bf3c4ca-4898-4353-f92b-6e7aceaa8cf7"},"source":["df_info_all_v2['log_share'].describe()"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["count    20363.000000\n","mean         3.104575\n","std          0.805235\n","min          1.609438\n","25%          2.484907\n","50%          2.995732\n","75%          3.688879\n","max          4.997212\n","Name: log_share, dtype: float64"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"4ciqO-MpXGAi"},"source":["## (1).Check the number of tokens in text"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":333},"id":"17x3PgGp8w6V","executionInfo":{"status":"ok","timestamp":1619562202878,"user_tz":240,"elapsed":201340,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"7c03a365-6d75-4c91-e429-8d66797b0771"},"source":["token_lens = []\n","for txt in df_info_all_v2['clean_text']:\n","    tokens = tokenizer.encode(txt, max_length=512)\n","    token_lens.append(len(tokens))\n","sns.distplot(token_lens)\n","plt.xlim([0, 512]);\n","plt.xlabel('Token count');"],"execution_count":25,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n","  warnings.warn(msg, FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"m12ZZqDJ--Ny","executionInfo":{"status":"ok","timestamp":1619509751645,"user_tz":240,"elapsed":185,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["MAX_LEN = 512"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ycLcU550cXPo"},"source":["## (2).Check the number of tokens in title"]},{"cell_type":"code","metadata":{"id":"pTo7C9MwdH4T","executionInfo":{"status":"ok","timestamp":1619562741466,"user_tz":240,"elapsed":186,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["df_info_all_v2['clean_title'].fillna('', inplace=True)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":333},"id":"T9d5xFBBcW7p","executionInfo":{"status":"ok","timestamp":1619562763770,"user_tz":240,"elapsed":657,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"8e4437b2-fceb-475f-c9c7-ea9fe0c5913a"},"source":["token_lens = []\n","for txt in df_info_all_v2['clean_title']:\n","    tokens = tokenizer.encode(txt, max_length=512)\n","    token_lens.append(len(tokens))\n","sns.distplot(token_lens)\n","plt.xlim([0, 100]);\n","plt.xlabel('Token count');"],"execution_count":39,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n","  warnings.warn(msg, FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"ggNusbFodqyH","executionInfo":{"status":"ok","timestamp":1619562795295,"user_tz":240,"elapsed":196,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["MAX_TITLE_LEN = 20"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364},"id":"CG7AsVB8cVj5","executionInfo":{"status":"ok","timestamp":1619562845681,"user_tz":240,"elapsed":301,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"33251bea-e989-4fb9-eee3-e2568d1c941d"},"source":["df_info_all_v2_oh = pd.get_dummies(df_info_all_v2, columns=['doc_topic', 'country_label', 'site_label'])\n","df_info_all_v2_oh.head(2)"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>uuid</th>\n","      <th>author</th>\n","      <th>country</th>\n","      <th>published</th>\n","      <th>image</th>\n","      <th>site</th>\n","      <th>site_category</th>\n","      <th>page_view</th>\n","      <th>fb_comment</th>\n","      <th>fb_likes</th>\n","      <th>fb_shares</th>\n","      <th>linkedin</th>\n","      <th>pinterest</th>\n","      <th>url</th>\n","      <th>date</th>\n","      <th>year</th>\n","      <th>month</th>\n","      <th>day</th>\n","      <th>weekday</th>\n","      <th>hour</th>\n","      <th>minute</th>\n","      <th>seccont</th>\n","      <th>noweek</th>\n","      <th>log_share</th>\n","      <th>num_title_words</th>\n","      <th>num_words</th>\n","      <th>num_words_clean</th>\n","      <th>country_model</th>\n","      <th>site_model</th>\n","      <th>log_page</th>\n","      <th>positive</th>\n","      <th>clean_title</th>\n","      <th>clean_text</th>\n","      <th>doc_topic_0</th>\n","      <th>doc_topic_1</th>\n","      <th>doc_topic_2</th>\n","      <th>doc_topic_3</th>\n","      <th>doc_topic_4</th>\n","      <th>doc_topic_5</th>\n","      <th>doc_topic_6</th>\n","      <th>...</th>\n","      <th>doc_topic_12</th>\n","      <th>doc_topic_13</th>\n","      <th>doc_topic_14</th>\n","      <th>doc_topic_15</th>\n","      <th>doc_topic_16</th>\n","      <th>doc_topic_17</th>\n","      <th>doc_topic_18</th>\n","      <th>doc_topic_19</th>\n","      <th>doc_topic_20</th>\n","      <th>doc_topic_21</th>\n","      <th>doc_topic_22</th>\n","      <th>doc_topic_23</th>\n","      <th>doc_topic_24</th>\n","      <th>country_label_0</th>\n","      <th>country_label_1</th>\n","      <th>country_label_2</th>\n","      <th>country_label_3</th>\n","      <th>country_label_4</th>\n","      <th>country_label_5</th>\n","      <th>country_label_6</th>\n","      <th>country_label_7</th>\n","      <th>country_label_8</th>\n","      <th>country_label_9</th>\n","      <th>country_label_10</th>\n","      <th>site_label_0</th>\n","      <th>site_label_1</th>\n","      <th>site_label_2</th>\n","      <th>site_label_3</th>\n","      <th>site_label_4</th>\n","      <th>site_label_5</th>\n","      <th>site_label_6</th>\n","      <th>site_label_7</th>\n","      <th>site_label_8</th>\n","      <th>site_label_9</th>\n","      <th>site_label_10</th>\n","      <th>site_label_11</th>\n","      <th>site_label_12</th>\n","      <th>site_label_13</th>\n","      <th>site_label_14</th>\n","      <th>site_label_15</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9b265eb1f08a07a093f4e415f4878b5ccec71b0b</td>\n","      <td>David E. Sanger, Julian E. Barnes and Nicole P...</td>\n","      <td>US</td>\n","      <td>2021-03-15T01:58:58.000+02:00</td>\n","      <td>0</td>\n","      <td>www.msn.com</td>\n","      <td>tech</td>\n","      <td>578.0</td>\n","      <td>17</td>\n","      <td>28</td>\n","      <td>107</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>https://www.msn.com/en-us/news/politics/white-...</td>\n","      <td>2021-03-15 01:58:58</td>\n","      <td>2021</td>\n","      <td>3</td>\n","      <td>15</td>\n","      <td>Mon</td>\n","      <td>1</td>\n","      <td>58</td>\n","      <td>6314338.0</td>\n","      <td>11</td>\n","      <td>4.682131</td>\n","      <td>11</td>\n","      <td>54</td>\n","      <td>26</td>\n","      <td>US</td>\n","      <td>www.msn.com</td>\n","      <td>6.361302</td>\n","      <td>0.012595</td>\n","      <td>white house weigh new cybersecurity approach f...</td>\n","      <td>washington sophisticated hack pull russia chin...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0d49c01d17674d04754b87cb7c5167a589934e61</td>\n","      <td>Marina Pitofsky</td>\n","      <td>US</td>\n","      <td>2021-03-15T01:58:57.000+02:00</td>\n","      <td>0</td>\n","      <td>www.msn.com</td>\n","      <td>tech</td>\n","      <td>578.0</td>\n","      <td>396</td>\n","      <td>3438</td>\n","      <td>84</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>https://www.msn.com/en-us/news/politics/rachel...</td>\n","      <td>2021-03-15 01:58:57</td>\n","      <td>2021</td>\n","      <td>3</td>\n","      <td>15</td>\n","      <td>Mon</td>\n","      <td>1</td>\n","      <td>58</td>\n","      <td>6314337.0</td>\n","      <td>11</td>\n","      <td>4.442651</td>\n","      <td>10</td>\n","      <td>310</td>\n","      <td>177</td>\n","      <td>US</td>\n","      <td>www.msn.com</td>\n","      <td>6.361302</td>\n","      <td>0.174687</td>\n","      <td>rachel maddow win grammy audio recording book</td>\n","      <td>© getty image rachel maddow win grammy audio r...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2 rows × 85 columns</p>\n","</div>"],"text/plain":["                                       uuid  ... site_label_15\n","0  9b265eb1f08a07a093f4e415f4878b5ccec71b0b  ...             0\n","1  0d49c01d17674d04754b87cb7c5167a589934e61  ...             0\n","\n","[2 rows x 85 columns]"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Va-HhxveLU7","executionInfo":{"status":"ok","timestamp":1619562977723,"user_tz":240,"elapsed":178,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"bfe4c1ad-7faf-4c64-9057-69981ee03d8e"},"source":["df_info_all_v2.columns"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['uuid', 'author', 'country', 'published', 'image', 'site',\n","       'site_category', 'page_view', 'fb_comment', 'fb_likes', 'fb_shares',\n","       'linkedin', 'pinterest', 'url', 'date', 'year', 'month', 'day',\n","       'weekday', 'hour', 'minute', 'seccont', 'noweek', 'doc_topic',\n","       'log_share', 'num_title_words', 'num_words', 'num_words_clean',\n","       'country_model', 'site_model', 'country_label', 'site_label',\n","       'log_page', 'positive', 'clean_title', 'clean_text'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7b8-4KqmfPtt","executionInfo":{"status":"ok","timestamp":1619563189649,"user_tz":240,"elapsed":219,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"8e441d42-f6a8-41ee-9659-f1ac369037ed"},"source":["df_info_all_v2_oh.columns"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['uuid', 'author', 'country', 'published', 'image', 'site',\n","       'site_category', 'page_view', 'fb_comment', 'fb_likes', 'fb_shares',\n","       'linkedin', 'pinterest', 'url', 'date', 'year', 'month', 'day',\n","       'weekday', 'hour', 'minute', 'seccont', 'noweek', 'log_share',\n","       'num_title_words', 'num_words', 'num_words_clean', 'country_model',\n","       'site_model', 'log_page', 'positive', 'clean_title', 'clean_text',\n","       'doc_topic_0', 'doc_topic_1', 'doc_topic_2', 'doc_topic_3',\n","       'doc_topic_4', 'doc_topic_5', 'doc_topic_6', 'doc_topic_7',\n","       'doc_topic_8', 'doc_topic_9', 'doc_topic_10', 'doc_topic_11',\n","       'doc_topic_12', 'doc_topic_13', 'doc_topic_14', 'doc_topic_15',\n","       'doc_topic_16', 'doc_topic_17', 'doc_topic_18', 'doc_topic_19',\n","       'doc_topic_20', 'doc_topic_21', 'doc_topic_22', 'doc_topic_23',\n","       'doc_topic_24', 'country_label_0', 'country_label_1', 'country_label_2',\n","       'country_label_3', 'country_label_4', 'country_label_5',\n","       'country_label_6', 'country_label_7', 'country_label_8',\n","       'country_label_9', 'country_label_10', 'site_label_0', 'site_label_1',\n","       'site_label_2', 'site_label_3', 'site_label_4', 'site_label_5',\n","       'site_label_6', 'site_label_7', 'site_label_8', 'site_label_9',\n","       'site_label_10', 'site_label_11', 'site_label_12', 'site_label_13',\n","       'site_label_14', 'site_label_15'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"gClCrC5Reg1z","executionInfo":{"status":"ok","timestamp":1619563255888,"user_tz":240,"elapsed":388,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["col = ['image','doc_topic',\n","       'log_share', 'num_words_clean',\n","       'country_label', 'site_label',\n","       'log_page', 'positive', 'clean_title','clean_text']"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"juBAPNT8fOTp","executionInfo":{"status":"ok","timestamp":1619563392430,"user_tz":240,"elapsed":187,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["drop_x = ['uuid', 'author', 'country', 'published', 'site',\n","          'site_category', 'page_view', 'fb_comment', 'fb_likes', \n","          'fb_shares', 'linkedin', 'pinterest', 'url', 'date', \n","          'year', 'month', 'day','weekday', 'hour', 'minute', \n","          'seccont', 'noweek', 'num_title_words', 'num_words', \n","          'country_model', 'site_model']"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MFXrYxc8TgmY","executionInfo":{"status":"ok","timestamp":1619563413189,"user_tz":240,"elapsed":203,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"a5ed1632-96aa-41c9-abde-5737cedc1e8b"},"source":["df_model = df_info_all_v2[col]\n","df_model_oh = df_info_all_v2_oh.drop(drop_x, axis=1)\n","df_model_oh.columns"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['image', 'log_share', 'num_words_clean', 'log_page', 'positive',\n","       'clean_title', 'clean_text', 'doc_topic_0', 'doc_topic_1',\n","       'doc_topic_2', 'doc_topic_3', 'doc_topic_4', 'doc_topic_5',\n","       'doc_topic_6', 'doc_topic_7', 'doc_topic_8', 'doc_topic_9',\n","       'doc_topic_10', 'doc_topic_11', 'doc_topic_12', 'doc_topic_13',\n","       'doc_topic_14', 'doc_topic_15', 'doc_topic_16', 'doc_topic_17',\n","       'doc_topic_18', 'doc_topic_19', 'doc_topic_20', 'doc_topic_21',\n","       'doc_topic_22', 'doc_topic_23', 'doc_topic_24', 'country_label_0',\n","       'country_label_1', 'country_label_2', 'country_label_3',\n","       'country_label_4', 'country_label_5', 'country_label_6',\n","       'country_label_7', 'country_label_8', 'country_label_9',\n","       'country_label_10', 'site_label_0', 'site_label_1', 'site_label_2',\n","       'site_label_3', 'site_label_4', 'site_label_5', 'site_label_6',\n","       'site_label_7', 'site_label_8', 'site_label_9', 'site_label_10',\n","       'site_label_11', 'site_label_12', 'site_label_13', 'site_label_14',\n","       'site_label_15'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"markdown","metadata":{"id":"ImhWXgHMwpEl"},"source":["# 3.Create Neural Network without text"]},{"cell_type":"markdown","metadata":{"id":"Hgs5CoXawuOR"},"source":["## (1).Dataset"]},{"cell_type":"code","metadata":{"id":"Li8kAzgiwtcN","executionInfo":{"status":"ok","timestamp":1619572580255,"user_tz":240,"elapsed":214,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["class NewsDataset(Dataset):\n","    def __init__(self, df, shares):\n","        self.shares = shares\n","        self.df = df\n","\n","    def __len__(self):\n","        return self.df.shape[0]\n","\n","    def __getitem__(self, item):\n","        shares = self.shares[item]\n","        meta = self.df.iloc[item].values\n","        return {\n","            'meta': torch.tensor(meta,dtype=torch.float),\n","            'shares': torch.tensor(shares, dtype=torch.float)\n","            }"],"execution_count":178,"outputs":[]},{"cell_type":"code","metadata":{"id":"fEl_X3Xiw_dy","executionInfo":{"status":"ok","timestamp":1619572609683,"user_tz":240,"elapsed":364,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["def create_data_loader(df_all, batch_size):\n","    ds = NewsDataset(\n","            shares = df_all['log_share'].to_numpy(),\n","            df = df_all.drop(['log_share', 'clean_text', 'clean_title'], axis=1)\n","    )\n","    return DataLoader(\n","            ds,\n","            batch_size=batch_size,\n","            num_workers=2\n","        )"],"execution_count":179,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q46zts14xXMy","executionInfo":{"status":"ok","timestamp":1619572612340,"user_tz":240,"elapsed":220,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["BATCH_SIZE = 32\n","train_data_loader = create_data_loader(df_train, BATCH_SIZE)\n","val_data_loader = create_data_loader(df_val, BATCH_SIZE)\n","test_data_loader = create_data_loader(df_test, BATCH_SIZE)"],"execution_count":180,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zUMKIFesxFiF"},"source":["## (2).Network"]},{"cell_type":"code","metadata":{"id":"ViSsOq5D58EX","executionInfo":{"status":"ok","timestamp":1619572616138,"user_tz":240,"elapsed":208,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["class NewsRegressorWithoutBert(nn.Module):\n","    def __init__(self):\n","        super(NewsRegressorWithoutBert, self).__init__()\n","        self.mlp = nn.Sequential(\n","                          nn.Linear(56, 100),\n","                          nn.BatchNorm1d(100),\n","                          nn.Dropout(0.3),\n","                          nn.ReLU(),\n","                          nn.Linear(100, 1),\n","                          )\n","    def forward(self, meta):\n","        out_mlp = self.mlp(meta)\n","        return out_mlp"],"execution_count":181,"outputs":[]},{"cell_type":"code","metadata":{"id":"S8zGfT6c6MsI","executionInfo":{"status":"ok","timestamp":1619572619380,"user_tz":240,"elapsed":285,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["model_news_no_bert = NewsRegressorWithoutBert()\n","model_news_no_bert = model_news_no_bert.to(device)"],"execution_count":182,"outputs":[]},{"cell_type":"code","metadata":{"id":"n7P1N2tk6hdl","executionInfo":{"status":"ok","timestamp":1619572628754,"user_tz":240,"elapsed":214,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["EPOCHS = 30\n","optimizer = AdamW(model_news_no_bert.parameters(), lr=1e-5)\n","total_steps = len(train_data_loader) * EPOCHS\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps=0,\n","    num_training_steps=total_steps\n",")\n","loss_fn = nn.MSELoss().to(device)"],"execution_count":183,"outputs":[]},{"cell_type":"code","metadata":{"id":"ApdRvWB86s0L","executionInfo":{"status":"ok","timestamp":1619572646939,"user_tz":240,"elapsed":216,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["def train_epoch(model, data_loader,\n","                loss_fn, optimizer,\n","                device, scheduler):\n","    model = model.train()\n","    losses = []\n","    for d in data_loader:\n","        shares = d[\"shares\"].to(device)\n","        meta = d['meta'].to(device)\n","        outputs = model(\n","            meta = meta\n","            )\n","        loss = loss_fn(outputs, shares)\n","        losses.append(loss.item())\n","        loss.backward()\n","        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","    return np.mean(losses)"],"execution_count":184,"outputs":[]},{"cell_type":"code","metadata":{"id":"GAD_6yu36zwL","executionInfo":{"status":"ok","timestamp":1619572654291,"user_tz":240,"elapsed":209,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["def eval_model(model, data_loader, loss_fn, device):\n","    model = model.eval()\n","    losses = []\n","    predicts = []\n","    with torch.no_grad():\n","        for d in data_loader:\n","            shares = d[\"shares\"].to(device)\n","            meta = d['meta'].to(device)\n","            outputs = model(\n","                meta=meta\n","            )\n","        loss = loss_fn(outputs, shares)\n","        losses.append(loss.item())\n","    return np.mean(losses)"],"execution_count":185,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1pLXrmX864FP","executionInfo":{"status":"ok","timestamp":1619572825602,"user_tz":240,"elapsed":163131,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"5243d3af-8c68-4ebd-e26f-98f3bab8b28f"},"source":["%%time\n","history = defaultdict(list)\n","best_loss = np.inf\n","for epoch in range(EPOCHS):\n","    print(f'Epoch {epoch + 1}/{EPOCHS}')\n","    print('-' * 10)\n","    train_loss = train_epoch(\n","        model_news_no_bert,\n","        train_data_loader,\n","        loss_fn,\n","        optimizer,\n","        device,\n","        scheduler\n","    )\n","    print(f'Train loss {train_loss}')\n","    val_loss = eval_model(\n","        model_news_no_bert,\n","        val_data_loader,\n","        loss_fn,\n","        device\n","    )\n","    print(f'Val loss {val_loss}')\n","    print()\n","    history['train_loss'].append(train_loss)\n","    history['val_loss'].append(val_loss)\n","    if val_loss < best_loss:\n","        torch.save(model_news_no_bert.state_dict(), 'best_model_no_bert_state.bin')\n","        best_loss = val_loss"],"execution_count":186,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 9.852161625319836\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 8.322807312011719\n","\n","Epoch 2/30\n","----------\n","Train loss 9.095214687609205\n","Val loss 7.620917797088623\n","\n","Epoch 3/30\n","----------\n","Train loss 8.436405151965571\n","Val loss 7.027039527893066\n","\n","Epoch 4/30\n","----------\n","Train loss 7.849194817449533\n","Val loss 6.552353858947754\n","\n","Epoch 5/30\n","----------\n","Train loss 7.380033059213676\n","Val loss 6.278110027313232\n","\n","Epoch 6/30\n","----------\n","Train loss 6.935947615492577\n","Val loss 5.911959171295166\n","\n","Epoch 7/30\n","----------\n","Train loss 6.579928383172727\n","Val loss 5.694965839385986\n","\n","Epoch 8/30\n","----------\n","Train loss 6.16416841581756\n","Val loss 5.35505485534668\n","\n","Epoch 9/30\n","----------\n","Train loss 5.854440513311648\n","Val loss 5.1500420570373535\n","\n","Epoch 10/30\n","----------\n","Train loss 5.552927906372968\n","Val loss 4.922115802764893\n","\n","Epoch 11/30\n","----------\n","Train loss 5.25692468624489\n","Val loss 4.76334285736084\n","\n","Epoch 12/30\n","----------\n","Train loss 5.035890119683509\n","Val loss 4.625093460083008\n","\n","Epoch 13/30\n","----------\n","Train loss 4.849135204857471\n","Val loss 4.513493537902832\n","\n","Epoch 14/30\n","----------\n","Train loss 4.6738807229434745\n","Val loss 4.384315490722656\n","\n","Epoch 15/30\n","----------\n","Train loss 4.50916731264077\n","Val loss 4.308389186859131\n","\n","Epoch 16/30\n","----------\n","Train loss 4.345584253703847\n","Val loss 4.011425971984863\n","\n","Epoch 17/30\n","----------\n","Train loss 4.1112170958051495\n","Val loss 3.906761407852173\n","\n","Epoch 18/30\n","----------\n","Train loss 4.011119315670986\n","Val loss 3.8526055812835693\n","\n","Epoch 19/30\n","----------\n","Train loss 3.9022015447710077\n","Val loss 3.802239179611206\n","\n","Epoch 20/30\n","----------\n","Train loss 3.828969904020721\n","Val loss 3.7550761699676514\n","\n","Epoch 21/30\n","----------\n","Train loss 3.7721797611199173\n","Val loss 3.710008144378662\n","\n","Epoch 22/30\n","----------\n","Train loss 3.724754991484623\n","Val loss 3.682776927947998\n","\n","Epoch 23/30\n","----------\n","Train loss 3.668702075060676\n","Val loss 3.6542348861694336\n","\n","Epoch 24/30\n","----------\n","Train loss 3.619785828450147\n","Val loss 3.627812385559082\n","\n","Epoch 25/30\n","----------\n","Train loss 3.589846009600396\n","Val loss 3.6014156341552734\n","\n","Epoch 26/30\n","----------\n","Train loss 3.557764597500072\n","Val loss 3.584003210067749\n","\n","Epoch 27/30\n","----------\n","Train loss 3.5503037714490704\n","Val loss 3.5726640224456787\n","\n","Epoch 28/30\n","----------\n","Train loss 3.512531228158988\n","Val loss 3.5605289936065674\n","\n","Epoch 29/30\n","----------\n","Train loss 3.51504236202614\n","Val loss 3.556851387023926\n","\n","Epoch 30/30\n","----------\n","Train loss 3.5128024608481163\n","Val loss 3.555640697479248\n","\n","CPU times: user 1min 29s, sys: 21.3 s, total: 1min 51s\n","Wall time: 2min 42s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312},"id":"4gwKkrPM-oVs","executionInfo":{"status":"ok","timestamp":1619572830057,"user_tz":240,"elapsed":484,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"1d76e6c7-f83f-402e-f2a3-68f394abe9e7"},"source":["plt.plot(history['train_loss'], label='train loss')\n","plt.plot(history['val_loss'], label='validation loss')\n","plt.title('Training history')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend()"],"execution_count":187,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7f510c509cd0>"]},"metadata":{"tags":[]},"execution_count":187},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"358QGhCK_rnm","executionInfo":{"status":"ok","timestamp":1619572984967,"user_tz":240,"elapsed":895,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["with torch.no_grad():\n","    prediction = []\n","    shares_list = []\n","    for i, d in enumerate(test_data_loader):\n","        shares = d[\"shares\"].to(device)\n","        meta = d['meta'].to(device)\n","        outputs = model_news_no_bert(\n","            meta=meta\n","        )\n","        shares_list += shares.tolist()\n","        prediction += outputs.flatten().tolist()"],"execution_count":190,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0eIv-BH7BRgq","executionInfo":{"status":"ok","timestamp":1619572989157,"user_tz":240,"elapsed":194,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"07d503f3-ebdd-4ba2-97c5-4feb121cd4ba"},"source":["mean_squared_error(shares_list, prediction)"],"execution_count":191,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4.034304218217329"]},"metadata":{"tags":[]},"execution_count":191}]},{"cell_type":"markdown","metadata":{"id":"zZGk6-oBhhnn"},"source":["# 3.Create Network with title"]},{"cell_type":"markdown","metadata":{"id":"qFESFzCzlGxJ"},"source":["## (1).Dataset"]},{"cell_type":"code","metadata":{"id":"p3HzzTj7--Le","executionInfo":{"status":"ok","timestamp":1619573367443,"user_tz":240,"elapsed":190,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["class NewsDataset(Dataset):\n","    def __init__(self, title, df, shares, tokenizer, max_len):\n","        self.title = title\n","        self.shares = shares\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        self.df = df\n","\n","    def __len__(self):\n","        return len(self.title)\n","\n","    def __getitem__(self, item):\n","        title = str(self.title[item])\n","        shares = self.shares[item]\n","        meta = self.df.iloc[item].values\n","        encoding = self.tokenizer.encode_plus(\n","            title,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            return_token_type_ids=False,\n","            pad_to_max_length=True,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","            )\n","        return {\n","            'title': title,\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'meta': torch.tensor(meta,dtype=torch.float),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'shares': torch.tensor(shares, dtype=torch.float)\n","            }"],"execution_count":205,"outputs":[]},{"cell_type":"code","metadata":{"id":"6VCzeaCF--JV","executionInfo":{"status":"ok","timestamp":1619573114131,"user_tz":240,"elapsed":348,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["df_train, df_test = train_test_split(\n","    df_model_oh,\n","    test_size=0.2,\n","    random_state=RANDOM_SEED\n","    )\n","df_val, df_test = train_test_split(\n","    df_test,\n","    test_size=0.5,\n","    random_state=RANDOM_SEED\n","    )"],"execution_count":194,"outputs":[]},{"cell_type":"code","metadata":{"id":"zDbKixFwFKro","executionInfo":{"status":"ok","timestamp":1619573385882,"user_tz":240,"elapsed":190,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["def create_data_loader(df_all, tokenizer, max_len, batch_size):\n","    ds = NewsDataset(\n","            title = df_all['clean_title'].to_numpy(),\n","            shares = df_all['log_share'].to_numpy(),\n","            tokenizer = tokenizer,\n","            df = df_all.drop(['log_share', 'clean_text', 'clean_title'], axis=1),\n","            max_len = max_len\n","    )\n","    return DataLoader(\n","            ds,\n","            batch_size=batch_size,\n","            num_workers=2\n","        )"],"execution_count":207,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ds-5khMa--Ea","executionInfo":{"status":"ok","timestamp":1619573387206,"user_tz":240,"elapsed":198,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["BATCH_SIZE = 16\n","train_data_loader = create_data_loader(df_train, tokenizer, MAX_TITLE_LEN, BATCH_SIZE)\n","val_data_loader = create_data_loader(df_val, tokenizer, MAX_TITLE_LEN, BATCH_SIZE)\n","test_data_loader = create_data_loader(df_test, tokenizer, MAX_TITLE_LEN, BATCH_SIZE)"],"execution_count":208,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BISRPX74jkHW","executionInfo":{"status":"ok","timestamp":1619564328311,"user_tz":240,"elapsed":284,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"2d0d0ff9-1a25-4c94-a5ed-87b9bfc1daf3"},"source":["df_model_oh.columns"],"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['image', 'log_share', 'num_words_clean', 'log_page', 'positive',\n","       'clean_title', 'clean_text', 'doc_topic_0', 'doc_topic_1',\n","       'doc_topic_2', 'doc_topic_3', 'doc_topic_4', 'doc_topic_5',\n","       'doc_topic_6', 'doc_topic_7', 'doc_topic_8', 'doc_topic_9',\n","       'doc_topic_10', 'doc_topic_11', 'doc_topic_12', 'doc_topic_13',\n","       'doc_topic_14', 'doc_topic_15', 'doc_topic_16', 'doc_topic_17',\n","       'doc_topic_18', 'doc_topic_19', 'doc_topic_20', 'doc_topic_21',\n","       'doc_topic_22', 'doc_topic_23', 'doc_topic_24', 'country_label_0',\n","       'country_label_1', 'country_label_2', 'country_label_3',\n","       'country_label_4', 'country_label_5', 'country_label_6',\n","       'country_label_7', 'country_label_8', 'country_label_9',\n","       'country_label_10', 'site_label_0', 'site_label_1', 'site_label_2',\n","       'site_label_3', 'site_label_4', 'site_label_5', 'site_label_6',\n","       'site_label_7', 'site_label_8', 'site_label_9', 'site_label_10',\n","       'site_label_11', 'site_label_12', 'site_label_13', 'site_label_14',\n","       'site_label_15'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"markdown","metadata":{"id":"P4fegm_blJcK"},"source":["## (2).Network"]},{"cell_type":"code","metadata":{"id":"bKA_DzoW--Bk","executionInfo":{"status":"ok","timestamp":1619573342989,"user_tz":240,"elapsed":226,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["class NewsRegressor(nn.Module):\n","    def __init__(self):\n","        super(NewsRegressor, self).__init__()\n","        self.bert = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',\n","                                                                        num_labels = 1)\n","        self.mlp = nn.Sequential(\n","                          nn.Linear(57, 100),\n","                          nn.BatchNorm1d(100),\n","                          nn.Dropout(0.3),\n","                          nn.ReLU(),\n","                          nn.Linear(100, 1),\n","                          )\n","    def forward(self, input_ids, attention_mask, meta):\n","        bert_output = self.bert(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask\n","            )\n","        input = torch.cat((meta, bert_output.logits), axis=1)\n","        out_mlp = self.mlp(input)\n","        return out_mlp"],"execution_count":201,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XeMSdTBI-9_G","executionInfo":{"status":"ok","timestamp":1619573394421,"user_tz":240,"elapsed":2599,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"c40c98ab-9343-48c1-a6fc-a8fe7397533e"},"source":["model_news = NewsRegressor()\n","model_news = model_news.to(device)"],"execution_count":209,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iPgRV_KwNDGG","executionInfo":{"status":"ok","timestamp":1619573349627,"user_tz":240,"elapsed":367,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"7c9b57d5-95f8-4945-e75a-8c8736c39b8e"},"source":["gc.collect()"],"execution_count":203,"outputs":[{"output_type":"execute_result","data":{"text/plain":["538"]},"metadata":{"tags":[]},"execution_count":203}]},{"cell_type":"code","metadata":{"id":"SbogHnP--98f","executionInfo":{"status":"ok","timestamp":1619573396329,"user_tz":240,"elapsed":270,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["EPOCHS = 30\n","optimizer = AdamW(model_news.parameters(), lr=1e-5)\n","total_steps = len(train_data_loader) * EPOCHS\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps=0,\n","    num_training_steps=total_steps\n",")\n","loss_fn = nn.MSELoss().to(device)"],"execution_count":210,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fjc4JOWZ-951","executionInfo":{"status":"ok","timestamp":1619573414145,"user_tz":240,"elapsed":197,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["def train_epoch(model, data_loader,\n","                loss_fn, optimizer,\n","                device, scheduler):\n","    model = model.train()\n","    losses = []\n","    for d in data_loader:\n","        input_ids = d[\"input_ids\"].to(device)\n","        attention_mask = d[\"attention_mask\"].to(device)\n","        shares = d[\"shares\"].to(device)\n","        meta = d['meta'].to(device)\n","        outputs = model(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            meta = meta\n","            )\n","        loss = loss_fn(outputs, shares)\n","        losses.append(loss.item())\n","        loss.backward()\n","        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","    return np.mean(losses)"],"execution_count":213,"outputs":[]},{"cell_type":"code","metadata":{"id":"GPiIAEn5-928","executionInfo":{"status":"ok","timestamp":1619573415187,"user_tz":240,"elapsed":238,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}}},"source":["def eval_model(model, data_loader, loss_fn, device):\n","    model = model.eval()\n","    losses = []\n","    with torch.no_grad():\n","        for d in data_loader:\n","            input_ids = d[\"input_ids\"].to(device)\n","            attention_mask = d[\"attention_mask\"].to(device)\n","            shares = d[\"shares\"].to(device)\n","            meta = d['meta'].to(device)\n","            outputs = model(\n","                input_ids=input_ids,\n","                attention_mask=attention_mask,\n","                meta=meta\n","            )\n","        loss = loss_fn(outputs, shares)\n","        losses.append(loss.item())\n","    return np.mean(losses)"],"execution_count":214,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KZcQd0to-9zo","executionInfo":{"status":"ok","timestamp":1619574965512,"user_tz":240,"elapsed":1519756,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"7656fb37-1bfd-4484-bbcb-1643fefbc88f"},"source":["%%time\n","history_bert = defaultdict(list)\n","best_loss = np.inf\n","for epoch in range(EPOCHS):\n","    print(f'Epoch {epoch + 1}/{EPOCHS}')\n","    print('-' * 10)\n","    train_loss = train_epoch(\n","        model_news,\n","        train_data_loader,\n","        loss_fn,\n","        optimizer,\n","        device,\n","        scheduler\n","    )\n","    print(f'Train loss {train_loss}')\n","    val_loss = eval_model(\n","        model_news,\n","        val_data_loader,\n","        loss_fn,\n","        device\n","    )\n","    print(f'Val loss {val_loss}')\n","    print()\n","    history_bert['train_loss'].append(train_loss)\n","    history_bert['val_loss'].append(val_loss)\n","    if val_loss < best_loss:\n","        torch.save(model_news.state_dict(), 'best_model_bert_state.bin')\n","        best_loss = val_loss"],"execution_count":215,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 7.297072545118023\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 7.617204189300537\n","\n","Epoch 2/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 5.971201148187564\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 6.939640998840332\n","\n","Epoch 3/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 5.122546714234282\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 5.567416667938232\n","\n","Epoch 4/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 4.066521717357916\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 3.6922199726104736\n","\n","Epoch 5/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 2.871684366166299\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 2.4478530883789062\n","\n","Epoch 6/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 2.0162124447780454\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 1.688042163848877\n","\n","Epoch 7/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.7309808475755966\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 1.3318443298339844\n","\n","Epoch 8/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.4826366992062279\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 1.2433555126190186\n","\n","Epoch 9/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.548322213204967\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 1.1603360176086426\n","\n","Epoch 10/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.437852439690853\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 1.8098526000976562\n","\n","Epoch 11/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.7655024343957142\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 1.900052547454834\n","\n","Epoch 12/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.542009813862764\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 1.3676679134368896\n","\n","Epoch 13/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.5544173526225777\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 2.3627257347106934\n","\n","Epoch 14/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.5421019933818017\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 1.1124504804611206\n","\n","Epoch 15/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.3726089027023878\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 1.2323521375656128\n","\n","Epoch 16/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.5309418816561788\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 1.5019631385803223\n","\n","Epoch 17/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.3792806275634935\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 2.1818437576293945\n","\n","Epoch 18/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.455057320580749\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 2.2872772216796875\n","\n","Epoch 19/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.3326838177658975\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 1.3819611072540283\n","\n","Epoch 20/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.3692086272899489\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 1.2503284215927124\n","\n","Epoch 21/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.4072576166661612\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 1.4158148765563965\n","\n","Epoch 22/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.353700401475315\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 1.0664398670196533\n","\n","Epoch 23/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.3240878964546736\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 1.0543887615203857\n","\n","Epoch 24/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.342477759300668\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 1.153409481048584\n","\n","Epoch 25/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.3079000732206152\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 1.1253623962402344\n","\n","Epoch 26/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.2749702725139052\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 1.1564463376998901\n","\n","Epoch 27/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.5811428107738026\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 1.553750991821289\n","\n","Epoch 28/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.6810916128465074\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 1.589547872543335\n","\n","Epoch 29/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.542549908512123\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 1.3866157531738281\n","\n","Epoch 30/30\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 1.434743652838603\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss 1.3567278385162354\n","\n","CPU times: user 23min 43s, sys: 1min 14s, total: 24min 58s\n","Wall time: 25min 19s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312},"id":"1DXRY_zTnMIH","executionInfo":{"status":"ok","timestamp":1619575110875,"user_tz":240,"elapsed":454,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"e30cf41a-d5b9-443d-a1b0-3e33af67193d"},"source":["plt.plot(history_bert['train_loss'], label='train loss')\n","plt.plot(history_bert['val_loss'], label='validation loss')\n","plt.title('Training history')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend()"],"execution_count":216,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7f510c3c6f90>"]},"metadata":{"tags":[]},"execution_count":216},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uMIBUIVPtCvt","executionInfo":{"status":"ok","timestamp":1619575262179,"user_tz":240,"elapsed":2269,"user":{"displayName":"HM","photoUrl":"","userId":"12637397841890976833"}},"outputId":"f8922cc4-0534-4ce2-d1ad-b2a66d43dad6"},"source":["with torch.no_grad():\n","    prediction = []\n","    shares_list = []\n","    for i, d in enumerate(test_data_loader):\n","        input_ids = d[\"input_ids\"].to(device)\n","        attention_mask = d[\"attention_mask\"].to(device)\n","        shares = d[\"shares\"].to(device)\n","        meta = d['meta'].to(device)\n","        outputs = model_news(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            meta=meta\n","        )\n","        shares_list += shares.tolist()\n","        prediction += outputs.flatten().tolist()\n","mean_squared_error(prediction, shares_list)"],"execution_count":219,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["1.2779957266333348"]},"metadata":{"tags":[]},"execution_count":219}]},{"cell_type":"markdown","metadata":{"id":"MX4KumPlwjYa"},"source":["# 4.Create Network with generate model\n","Please see SI630_project_code_3.ipynb"]},{"cell_type":"code","metadata":{"id":"i0geHoOFGVLN"},"source":[],"execution_count":null,"outputs":[]}]}